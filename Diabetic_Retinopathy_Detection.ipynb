{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyNS77pOlRC6EVYACJHR+ZNE",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "premium",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/madynamics/Noise-modelling/blob/main/Diabetic_Retinopathy_Detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "0. Download data from Kaggle or Google Drive"
      ],
      "metadata": {
        "id": "o8lhISPr_8a7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pPlHQaRAf2p5"
      },
      "outputs": [],
      "source": [
        "## DO NOT START HERE, START FROM '# 0.get the data' below\n",
        "\n",
        "!pip install kaggle\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "! mkdir /root/.kaggle\n",
        "!cp /content/drive/MyDrive/ColabNotebooks/kaggle/kaggle.json /root/.kaggle/kaggle.json\n",
        "! chmod 600 /root/.kaggle/kaggle.json\n",
        "! kaggle competitions download -c diabetic-retinopathy-detection"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! unzip /content/diabetic-retinopathy-detection.zip"
      ],
      "metadata": {
        "id": "efob7RL3dcCA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!rm /content/diabetic-retinopathy-detection.zip"
      ],
      "metadata": {
        "id": "xla-mljaDgOJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cat test.zip.* > test.zip"
      ],
      "metadata": {
        "id": "q1tMSHTv7m--"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!rm /content/test.zip.001\n",
        "!rm /content/test.zip.002\n",
        "!rm /content/test.zip.003\n",
        "!rm /content/test.zip.004\n",
        "!rm /content/test.zip.005\n",
        "!rm /content/test.zip.006\n",
        "!rm /content/test.zip.007"
      ],
      "metadata": {
        "id": "d4h88T0qE2LM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cat train.zip.* > train.zip"
      ],
      "metadata": {
        "id": "9E6XbbT3FGjW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!rm /content/train.zip.001\n",
        "!rm /content/train.zip.002\n",
        "!rm /content/train.zip.003\n",
        "!rm /content/train.zip.004\n",
        "!rm /content/train.zip.005"
      ],
      "metadata": {
        "id": "7Kgv_Pb8F701"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! unzip /content/test.zip\n",
        "! unzip /content/train.zip\n",
        "! unzip /content/trainLabels.csv.zip"
      ],
      "metadata": {
        "id": "FWkJrmpMGE2m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!rm /content/train.zip\n",
        "!rm /content/test.zip\n",
        "!rm /content/trainLabels.csv.zip"
      ],
      "metadata": {
        "id": "MLcxg7b_KiF3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir /content/DiabeticRetinopathyDetection\n",
        "!mv /content/test/ /content/DiabeticRetinopathyDetection\n",
        "!mv /content/train/ /content/DiabeticRetinopathyDetection\n",
        "!mv /content/trainLabels.csv /content/DiabeticRetinopathyDetection"
      ],
      "metadata": {
        "id": "7prvmjRJK0f2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mv /content/DiabeticRetinopathyDetection/ /content/drive/MyDrive/"
      ],
      "metadata": {
        "id": "uGy4dNClQyrp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-R15qB1VDtIj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 0.get the data\n",
        "\n",
        "!pip install kaggle\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fv0ZrknSDtgC",
        "outputId": "faff0cdf-ccd1-4cbf-ad8c-e51b3386ed5e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.8/dist-packages (1.5.12)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.8/dist-packages (from kaggle) (1.15.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from kaggle) (2.25.1)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.8/dist-packages (from kaggle) (2.8.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from kaggle) (4.64.1)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.8/dist-packages (from kaggle) (8.0.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.8/dist-packages (from kaggle) (2022.12.7)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.8/dist-packages (from kaggle) (1.24.3)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.8/dist-packages (from python-slugify->kaggle) (1.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->kaggle) (2.10)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->kaggle) (4.0.0)\n",
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Data Pre-processing"
      ],
      "metadata": {
        "id": "m63hSIlMAF3U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## NEED NOT EXECUTE, GO TO NEXT CELL\n",
        "\n",
        "## pre-processing to enlarge the portion of retina\n",
        "\n",
        "## takes a lot of time\n",
        "import os\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import warnings\n",
        "from multiprocessing import Pool\n",
        "import cv2\n",
        "from tqdm import tqdm\n",
        "\n",
        "def trim(im):\n",
        "    \"\"\"\n",
        "    Converts image to grayscale using cv2, then computes binary matrix\n",
        "    of the pixels that are above a certain threshold, then takes out\n",
        "    the first row where a certain percetage of the pixels are above the\n",
        "    threshold will be the first clip point. Same idea for col, max row, max col.\n",
        "    \"\"\"\n",
        "    percentage = 0.02\n",
        "\n",
        "    img = np.array(im)\n",
        "    img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "    im = img_gray > 0.1 * np.mean(img_gray[img_gray != 0])\n",
        "    row_sums = np.sum(im, axis=1)\n",
        "    col_sums = np.sum(im, axis=0)\n",
        "    rows = np.where(row_sums > img.shape[1] * percentage)[0]\n",
        "    cols = np.where(col_sums > img.shape[0] * percentage)[0]\n",
        "    min_row, min_col = np.min(rows), np.min(cols)\n",
        "    max_row, max_col = np.max(rows), np.max(cols)\n",
        "    im_crop = img[min_row : max_row + 1, min_col : max_col + 1]\n",
        "    return Image.fromarray(im_crop)\n",
        "\n",
        "\n",
        "def resize_maintain_aspect(image, desired_size):\n",
        "    \"\"\"\n",
        "    Stole this from some stackoverflow post but can't remember which,\n",
        "    this will add padding to maintain the aspect ratio.\n",
        "    \"\"\"\n",
        "    old_size = image.size  # old_size[0] is in (width, height) format\n",
        "    ratio = float(desired_size) / max(old_size)\n",
        "    new_size = tuple([int(x * ratio) for x in old_size])\n",
        "    im = image.resize(new_size, Image.ANTIALIAS)\n",
        "    new_im = Image.new(\"RGB\", (desired_size, desired_size))\n",
        "    new_im.paste(im, ((desired_size - new_size[0]) // 2, (desired_size - new_size[1]) // 2))\n",
        "    return new_im\n",
        "\n",
        "def save_single(args):\n",
        "    img_file, input_path_folder, output_path_folder, output_size = args\n",
        "    if img_file.startswith('.ipynb_checkpoints'):\n",
        "        return\n",
        "    input_path = os.path.join(input_path_folder, img_file)\n",
        "    output_path = os.path.join(output_path_folder, img_file)\n",
        "    if os.path.exists(output_path):\n",
        "        return\n",
        "    image_original = Image.open(input_path)\n",
        "    image = trim(image_original)\n",
        "    image = resize_maintain_aspect(image, desired_size=output_size[0])\n",
        "    image.save(output_path)\n",
        "\n",
        "\n",
        "def fast_image_resize(input_path_folder, output_path_folder, output_size=None):\n",
        "    \"\"\"\n",
        "    Uses multiprocessing to make it fast\n",
        "    \"\"\"\n",
        "    if not output_size:\n",
        "        warnings.warn(\"Need to specify output_size! For example: output_size=100\")\n",
        "        exit()\n",
        "\n",
        "    if not os.path.exists(output_path_folder):\n",
        "        os.makedirs(output_path_folder)\n",
        "\n",
        "    jobs = [\n",
        "        (file, input_path_folder, output_path_folder, output_size)\n",
        "        for file in os.listdir(input_path_folder)\n",
        "    ]\n",
        "\n",
        "    with Pool() as p:\n",
        "        list(tqdm(p.imap_unordered(save_single, jobs), total=len(jobs)))"
      ],
      "metadata": {
        "id": "DalTU-J4bGPn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## NEED NOT EXECUTE, GO TO NEXT CELL\n",
        "\n",
        "# if you believe the folder may be corrupted, you may use the following line\n",
        "# !rm -r /content/drive/MyDrive/DiabeticRetinopathyDetection/test_resized"
      ],
      "metadata": {
        "id": "tuqhk_Irjqwb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## NEED NOT EXECUTE, GO TO NEXT CELL\n",
        "# CHANGE SIZE (ONLY FOR PREPROCESSING)\n",
        "\n",
        "# fast_image_resize(\"/content/drive/MyDrive/DiabeticRetinopathyDetection/train/\", \"/content/drive/MyDrive/DiabeticRetinopathyDetection/train_resized/\", output_size=(CROP_W, CROP_H))\n",
        "fast_image_resize(\"/content/drive/MyDrive/DiabeticRetinopathyDetection/test/\", \"/content/drive/MyDrive/DiabeticRetinopathyDetection/test_resized/\", output_size=(728, 728))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VkNbc36Xj-dF",
        "outputId": "f4b7998c-9ea1-4290-ef5c-c80b68cccb85"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 53577/53577 [00:05<00:00, 9732.54it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1.preprocessing\n",
        "import pandas as pd\n",
        "\n",
        "trainLabel = pd.read_csv(\"/content/drive/MyDrive/DiabeticRetinopathyDetection/trainLabels.csv\")\n",
        "\n",
        "trainLabel.iloc[0:1208,:].to_csv(\"valLabel.csv\",index=False)\n",
        "trainLabel.iloc[1209:,:].to_csv(\"trainLabel.csv\",index=False)"
      ],
      "metadata": {
        "id": "xkf_Vw6p1mfm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Data loader"
      ],
      "metadata": {
        "id": "Mnl3_AZsAKTM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. define the dataset\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import albumentations as A\n",
        "from albumentations.pytorch import ToTensorV2\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "# Data augmentation for images\n",
        "train_transforms = A.Compose(\n",
        "    [\n",
        "        A.Resize(width=760, height=760),\n",
        "        A.RandomCrop(height=728, width=728),\n",
        "        A.HorizontalFlip(p=0.5),\n",
        "        A.VerticalFlip(p=0.5),\n",
        "        A.RandomRotate90(p=0.5),\n",
        "        A.Blur(p=0.3),\n",
        "        A.CLAHE(p=0.3),\n",
        "        A.ColorJitter(p=0.3),\n",
        "        A.CoarseDropout(max_holes=12, max_height=20, max_width=20, p=0.3),\n",
        "        A.Affine(shear=30, rotate=0, p=0.2, mode=\"constant\"),\n",
        "        A.Normalize(\n",
        "            mean=[0.3199, 0.2240, 0.1609],\n",
        "            std=[0.3020, 0.2183, 0.1741],\n",
        "            max_pixel_value=255.0,\n",
        "        ),\n",
        "        ToTensorV2(),\n",
        "    ]\n",
        ")\n",
        "\n",
        "val_transforms = A.Compose(\n",
        "    [\n",
        "        A.Resize(height=728, width=728),\n",
        "        A.Normalize(\n",
        "            mean=[0.3199, 0.2240, 0.1609],\n",
        "            std=[0.3020, 0.2183, 0.1741],\n",
        "            max_pixel_value=255.0,\n",
        "        ),\n",
        "        ToTensorV2(),\n",
        "    ]\n",
        ")\n",
        "\n",
        "class DRDataset(Dataset):\n",
        "    def __init__(self, images_folder, path_to_csv, train=True, transform=None):\n",
        "        super().__init__()\n",
        "        # each row of the csv file contains: 1) image name; 2) label\n",
        "        self.data = pd.read_csv(path_to_csv)\n",
        "        self.images_folder = images_folder\n",
        "        self.image_files = os.listdir(images_folder)\n",
        "        self.transform = transform\n",
        "        self.train = train\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.data.shape[0] if self.train else len(self.image_files)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        if self.train:\n",
        "            image_file, label = self.data.iloc[index]\n",
        "        else:\n",
        "            # if test simply return -1 for label, I do this in order to\n",
        "            # re-use same dataset class for test set submission later on\n",
        "            image_file, label = self.image_files[index], -1\n",
        "            image_file = image_file.replace(\".jpeg\", \"\")\n",
        "\n",
        "        # read it with Image.open from PIL to convert it into np.array, because we want to\n",
        "        # use albumentation\n",
        "        image = np.array(Image.open(os.path.join(self.images_folder, image_file+\".jpeg\")))\n",
        "\n",
        "        # send it to augmentation\n",
        "        if self.transform:\n",
        "            # this is the form that albumentation requires\n",
        "            image = self.transform(image=image)[\"image\"]\n",
        "\n",
        "        return image, label, image_file"
      ],
      "metadata": {
        "id": "dON1uX-ylzT6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Test if everything works ok\n",
        "\"\"\"\n",
        "dataset = DRDataset(\n",
        "    images_folder=\"/content/drive/MyDrive/DiabeticRetinopathyDetection/train_resized/\",\n",
        "    path_to_csv=\"/content/drive/MyDrive/DiabeticRetinopathyDetection/trainLabels.csv\",\n",
        "    transform=val_transforms,\n",
        ")\n",
        "loader = DataLoader(\n",
        "    dataset=dataset, batch_size=32, num_workers=2, shuffle=True, pin_memory=True\n",
        ")\n",
        "\n",
        "for x, label, file in tqdm(loader):\n",
        "    print(x.shape)\n",
        "    print(label.shape)\n",
        "    import sys\n",
        "    sys.exit()"
      ],
      "metadata": {
        "id": "Wnt544Ahwrx-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Training"
      ],
      "metadata": {
        "id": "5AwQtXr-ASQ-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. Define the methods for training\n",
        "\n",
        "!pip install efficientnet_pytorch\n",
        "\n",
        "def check_accuracy(loader, model, device=\"cuda\"):\n",
        "    model.eval()\n",
        "    all_preds, all_labels = [], []\n",
        "    num_correct = 0\n",
        "    num_samples = 0\n",
        "\n",
        "    for x, y, filename in tqdm(loader):\n",
        "        x = x.to(device=device)\n",
        "        y = y.to(device=device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            predictions = model(x)\n",
        "\n",
        "        # Convert MSE floats to integer predictions\n",
        "        predictions[predictions < 0.5] = 0\n",
        "        predictions[(predictions >= 0.5) & (predictions < 1.5)] = 1\n",
        "        predictions[(predictions >= 1.5) & (predictions < 2.5)] = 2\n",
        "        predictions[(predictions >= 2.5) & (predictions < 3.5)] = 3\n",
        "        predictions[(predictions >= 3.5) & (predictions < 100)] = 4\n",
        "        predictions = predictions.long().view(-1)\n",
        "        y = y.view(-1)\n",
        "\n",
        "        num_correct += (predictions == y).sum()\n",
        "        num_samples += predictions.shape[0]\n",
        "\n",
        "        # add to lists\n",
        "        all_preds.append(predictions.detach().cpu().numpy())\n",
        "        all_labels.append(y.detach().cpu().numpy())\n",
        "    \n",
        "    # though the accuracy is printed, it is not important for the game\n",
        "    print(\n",
        "        f\"Got {num_correct} / {num_samples} with accuracy {float(num_correct) / float(num_samples) * 100:.2f}\"\n",
        "    )\n",
        "    model.train()\n",
        "    # concatenate the predictions and labels, will be sent to 'cohen_kappa_score' the calculate\n",
        "    # the score in training\n",
        "    return np.concatenate(all_preds, axis=0, dtype=np.int64), np.concatenate(\n",
        "        all_labels, axis=0, dtype=np.int64\n",
        "    )\n",
        "\n",
        "\n",
        "def save_checkpoint(state, filename=\"my_checkpoint.pth.tar\"):\n",
        "    print(\"=> Saving checkpoint\")\n",
        "    torch.save(state, filename)\n",
        "\n",
        "\n",
        "def load_checkpoint(checkpoint, model, optimizer, lr):\n",
        "    print(\"=> Loading checkpoint\")\n",
        "    model.load_state_dict(checkpoint[\"state_dict\"])\n",
        "    #optimizer.load_state_dict(checkpoint[\"optimizer\"])\n",
        "\n",
        "    # If we don't do this then it will just have learning rate of old checkpoint\n",
        "    # and it will lead to many hours of debugging \\:\n",
        "    for param_group in optimizer.param_groups:\n",
        "        param_group[\"lr\"] = lr"
      ],
      "metadata": {
        "id": "FYd6YOgPwx4z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ee70ddfc-2b05-42dd-eb4a-a1e1f486b837"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: efficientnet_pytorch in /usr/local/lib/python3.8/dist-packages (0.7.1)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.8/dist-packages (from efficientnet_pytorch) (1.13.1+cu116)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch->efficientnet_pytorch) (4.5.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 4.0 training\n",
        "\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "LEARNING_RATE = 3e-5\n",
        "WEIGHT_DECAY = 5e-4\n",
        "BATCH_SIZE = 32\n",
        "NUM_EPOCHS = 200\n",
        "NUM_WORKERS = 6\n",
        "PIN_MEMORY = True\n",
        "SAVE_MODEL = True\n",
        "LOAD_MODEL = True\n",
        "\n",
        "from torch import nn, optim\n",
        "from efficientnet_pytorch import EfficientNet\n",
        "\n",
        "\n",
        "train_ds = DRDataset(\n",
        "    images_folder=\"/content/drive/MyDrive/DiabeticRetinopathyDetection/train_resized\",\n",
        "    path_to_csv=\"/content/trainLabel.csv\",\n",
        "    transform=val_transforms,\n",
        ")\n",
        "val_ds = DRDataset(\n",
        "    images_folder=\"/content/drive/MyDrive/DiabeticRetinopathyDetection/train_resized\",\n",
        "    path_to_csv=\"/content/valLabel.csv\",\n",
        "    transform=val_transforms,\n",
        ")\n",
        "\n",
        "train_loader = DataLoader(\n",
        "    train_ds,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    num_workers=NUM_WORKERS,\n",
        "    pin_memory=PIN_MEMORY,\n",
        "    shuffle=True,\n",
        ")\n",
        "val_loader = DataLoader(\n",
        "    val_ds,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    num_workers=2,\n",
        "    pin_memory=PIN_MEMORY,\n",
        "    shuffle=False,\n",
        ")\n",
        "loss_fn = nn.MSELoss()\n",
        "\n",
        "model = EfficientNet.from_pretrained(\"efficientnet-b3\")\n",
        "model._fc = nn.Linear(1536, 1)\n",
        "model = model.to(DEVICE)\n",
        "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY)\n",
        "scaler = torch.cuda.amp.GradScaler()\n",
        "\n",
        "def train_one_epoch(loader, model, optimizer, loss_fn, scaler, device):\n",
        "    losses = []\n",
        "    loop = tqdm(loader)\n",
        "    for batch_idx, (data, targets, _) in enumerate(loop):\n",
        "\n",
        "        data = data.to(device=device)\n",
        "        targets = targets.to(device=device)\n",
        "\n",
        "        # forward\n",
        "        with torch.cuda.amp.autocast():\n",
        "            scores = model(data)\n",
        "            loss = loss_fn(scores, targets.unsqueeze(1).float())\n",
        "\n",
        "        losses.append(loss.item())\n",
        "\n",
        "        # backward\n",
        "        optimizer.zero_grad()\n",
        "        scaler.scale(loss).backward()\n",
        "        scaler.step(optimizer)\n",
        "        scaler.update()\n",
        "        loop.set_postfix(loss=loss.item())\n",
        "\n",
        "    print(f\"Loss average over epoch: {sum(losses)/len(losses)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vNO2Xt5lzEyN",
        "outputId": "f19f71a8-48fa-4020-9fae-0666e6944c51"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded pretrained weights for efficientnet-b3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import cohen_kappa_score"
      ],
      "metadata": {
        "id": "sRh1Pxs4bijk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 4.1 training\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "    train_one_epoch(train_loader, model, optimizer, loss_fn, scaler, DEVICE)\n",
        "\n",
        "    # get on validation\n",
        "    preds, labels = check_accuracy(val_loader, model, DEVICE)\n",
        "    print(epoch)\n",
        "    print(f\"QuadraticWeightedKappa (Validation): {cohen_kappa_score(labels, preds, weights='quadratic')}\")\n",
        "\n",
        "    if SAVE_MODEL:\n",
        "        checkpoint = {\n",
        "            \"state_dict\": model.state_dict(),\n",
        "            \"optimizer\": optimizer.state_dict(),\n",
        "        }\n",
        "        save_checkpoint(checkpoint, filename=f\"b3_{epoch}.pth.tar\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "1q3pLhRdvzKD",
        "outputId": "d12a418b-7f10-4746-beed-2a18c3393f58"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1060/1060 [10:59<00:00,  1.61it/s, loss=0.34]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss average over epoch: 0.5541901853708726\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 38/38 [00:16<00:00,  2.36it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Got 882 / 1208 with accuracy 73.01\n",
            "0\n",
            "QuadraticWeightedKappa (Validation): 0.7298800671154084\n",
            "=> Saving checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1060/1060 [09:51<00:00,  1.79it/s, loss=0.224]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss average over epoch: 0.37624424409191565\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 38/38 [00:16<00:00,  2.36it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Got 931 / 1208 with accuracy 77.07\n",
            "1\n",
            "QuadraticWeightedKappa (Validation): 0.7780650846563655\n",
            "=> Saving checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1060/1060 [09:51<00:00,  1.79it/s, loss=0.282]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss average over epoch: 0.30744021071718547\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 38/38 [00:16<00:00,  2.37it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Got 945 / 1208 with accuracy 78.23\n",
            "2\n",
            "QuadraticWeightedKappa (Validation): 0.7899044370125953\n",
            "=> Saving checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1060/1060 [09:51<00:00,  1.79it/s, loss=0.397]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss average over epoch: 0.25663924141312544\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 38/38 [00:16<00:00,  2.36it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Got 940 / 1208 with accuracy 77.81\n",
            "3\n",
            "QuadraticWeightedKappa (Validation): 0.779978465922645\n",
            "=> Saving checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1060/1060 [09:51<00:00,  1.79it/s, loss=0.0803]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss average over epoch: 0.21391470796024462\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 38/38 [00:15<00:00,  2.38it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Got 939 / 1208 with accuracy 77.73\n",
            "4\n",
            "QuadraticWeightedKappa (Validation): 0.7969927472138687\n",
            "=> Saving checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1060/1060 [09:52<00:00,  1.79it/s, loss=0.368]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss average over epoch: 0.1820754911434257\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 38/38 [00:15<00:00,  2.38it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Got 945 / 1208 with accuracy 78.23\n",
            "5\n",
            "QuadraticWeightedKappa (Validation): 0.7884852399322378\n",
            "=> Saving checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1060/1060 [09:51<00:00,  1.79it/s, loss=0.209]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss average over epoch: 0.15361458376436582\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 38/38 [00:15<00:00,  2.38it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Got 968 / 1208 with accuracy 80.13\n",
            "6\n",
            "QuadraticWeightedKappa (Validation): 0.7727874441682618\n",
            "=> Saving checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1060/1060 [09:51<00:00,  1.79it/s, loss=0.0872]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss average over epoch: 0.13374521239432244\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 38/38 [00:15<00:00,  2.38it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Got 896 / 1208 with accuracy 74.17\n",
            "7\n",
            "QuadraticWeightedKappa (Validation): 0.7674467827348668\n",
            "=> Saving checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1060/1060 [09:51<00:00,  1.79it/s, loss=0.127]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss average over epoch: 0.11565393541219099\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 38/38 [00:16<00:00,  2.37it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Got 905 / 1208 with accuracy 74.92\n",
            "8\n",
            "QuadraticWeightedKappa (Validation): 0.7901867873539261\n",
            "=> Saving checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1060/1060 [09:51<00:00,  1.79it/s, loss=0.114]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss average over epoch: 0.10257884738439658\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 38/38 [00:16<00:00,  2.35it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Got 961 / 1208 with accuracy 79.55\n",
            "9\n",
            "QuadraticWeightedKappa (Validation): 0.7864711989403215\n",
            "=> Saving checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1060/1060 [09:51<00:00,  1.79it/s, loss=0.039]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss average over epoch: 0.09623268037190977\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 38/38 [00:15<00:00,  2.40it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Got 936 / 1208 with accuracy 77.48\n",
            "10\n",
            "QuadraticWeightedKappa (Validation): 0.7667025719699266\n",
            "=> Saving checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  3%|▎         | 37/1060 [00:22<10:32,  1.62it/s, loss=0.0349]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-4e0ddd6cb962>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# 4.1 training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mNUM_EPOCHS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mtrain_one_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscaler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDEVICE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;31m# get on validation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-8-a5f455f7c6c8>\u001b[0m in \u001b[0;36mtrain_one_epoch\u001b[0;34m(loader, model, optimizer, loss_fn, scaler, device)\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m         \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscale\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m         \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m         \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m         \u001b[0mloop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_postfix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/cuda/amp/grad_scaler.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, optimizer, *args, **kwargs)\u001b[0m\n\u001b[1;32m    339\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer_state\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"found_inf_per_device\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"No inf checks were recorded for this optimizer.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    340\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 341\u001b[0;31m         \u001b[0mretval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_opt_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    342\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    343\u001b[0m         \u001b[0moptimizer_state\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"stage\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mOptState\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSTEPPED\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/cuda/amp/grad_scaler.py\u001b[0m in \u001b[0;36m_maybe_opt_step\u001b[0;34m(self, optimizer, optimizer_state, *args, **kwargs)\u001b[0m\n\u001b[1;32m    285\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_maybe_opt_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    286\u001b[0m         \u001b[0mretval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 287\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0moptimizer_state\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"found_inf_per_device\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    288\u001b[0m             \u001b[0mretval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    289\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mretval\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/cuda/amp/grad_scaler.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    285\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_maybe_opt_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    286\u001b[0m         \u001b[0mretval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 287\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0moptimizer_state\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"found_inf_per_device\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    288\u001b[0m             \u001b[0mretval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    289\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mretval\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mv /content/b3_9.pth.tar /content/drive/MyDrive/DiabeticRetinopathyDetection/"
      ],
      "metadata": {
        "id": "MFRjbu3bNJzz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "LEARNING_RATE = 3e-6\n",
        "\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "    train_one_epoch(train_loader, model, optimizer, loss_fn, scaler, DEVICE)\n",
        "\n",
        "    # get on validation\n",
        "    preds, labels = check_accuracy(val_loader, model, DEVICE)\n",
        "    print(epoch)\n",
        "    print(f\"QuadraticWeightedKappa (Validation): {cohen_kappa_score(labels, preds, weights='quadratic')}\")\n",
        "\n",
        "    if SAVE_MODEL:\n",
        "        checkpoint = {\n",
        "            \"state_dict\": model.state_dict(),\n",
        "            \"optimizer\": optimizer.state_dict(),\n",
        "        }\n",
        "        save_checkpoint(checkpoint, filename=f\"b3_{epoch}.pth.tar\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 916
        },
        "id": "GSZNRNyx_UAq",
        "outputId": "48d3ca5b-2922-464c-f0e1-40196e6cc52a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1060/1060 [09:51<00:00,  1.79it/s, loss=0.0903]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss average over epoch: 0.3942960482161\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 38/38 [00:15<00:00,  2.39it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Got 911 / 1208 with accuracy 75.41\n",
            "0\n",
            "QuadraticWeightedKappa (Validation): 0.7546569582117789\n",
            "=> Saving checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1060/1060 [09:51<00:00,  1.79it/s, loss=0.0595]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss average over epoch: 0.16276580253967418\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 38/38 [00:15<00:00,  2.38it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Got 941 / 1208 with accuracy 77.90\n",
            "1\n",
            "QuadraticWeightedKappa (Validation): 0.7714324058194462\n",
            "=> Saving checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1060/1060 [09:51<00:00,  1.79it/s, loss=0.254]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss average over epoch: 0.11825784973554172\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 38/38 [00:16<00:00,  2.35it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Got 952 / 1208 with accuracy 78.81\n",
            "2\n",
            "QuadraticWeightedKappa (Validation): 0.7707778107183935\n",
            "=> Saving checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 30%|███       | 323/1060 [03:01<06:49,  1.80it/s, loss=0.0591]<ipython-input-2-bb891cd5760e>:72: DeprecationWarning: An exception was ignored while fetching the attribute `__array_interface__` from an object of type 'JpegImageFile'.  With the exception of `AttributeError` NumPy will always raise this exception in the future.  Raise this deprecation warning to see the original exception. (Warning added NumPy 1.21)\n",
            "  image = np.array(Image.open(os.path.join(self.images_folder, image_file+\".jpeg\")))\n",
            " 30%|███       | 323/1060 [03:01<06:55,  1.78it/s, loss=0.0591]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-30c475763d15>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mNUM_EPOCHS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mtrain_one_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscaler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDEVICE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;31m# get on validation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-8-a5f455f7c6c8>\u001b[0m in \u001b[0;36mtrain_one_epoch\u001b[0;34m(loader, model, optimizer, loss_fn, scaler, device)\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m         \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscale\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m         \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m         \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m         \u001b[0mloop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_postfix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/cuda/amp/grad_scaler.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, optimizer, *args, **kwargs)\u001b[0m\n\u001b[1;32m    339\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer_state\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"found_inf_per_device\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"No inf checks were recorded for this optimizer.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    340\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 341\u001b[0;31m         \u001b[0mretval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_opt_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    342\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    343\u001b[0m         \u001b[0moptimizer_state\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"stage\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mOptState\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSTEPPED\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/cuda/amp/grad_scaler.py\u001b[0m in \u001b[0;36m_maybe_opt_step\u001b[0;34m(self, optimizer, optimizer_state, *args, **kwargs)\u001b[0m\n\u001b[1;32m    285\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_maybe_opt_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    286\u001b[0m         \u001b[0mretval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 287\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0moptimizer_state\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"found_inf_per_device\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    288\u001b[0m             \u001b[0mretval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    289\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mretval\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/cuda/amp/grad_scaler.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    285\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_maybe_opt_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    286\u001b[0m         \u001b[0mretval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 287\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0moptimizer_state\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"found_inf_per_device\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    288\u001b[0m             \u001b[0mretval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    289\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mretval\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cp /content/drive/MyDrive/DiabeticRetinopathyDetection/b3_9.pth.tar /content/"
      ],
      "metadata": {
        "id": "i8P3HIsGVpp7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. Make submission"
      ],
      "metadata": {
        "id": "9pSNvv0BA3IU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# get result\n",
        "\n",
        "CHECKPOINT_FILE = \"b3_9.pth.tar\"\n",
        "\n",
        "if LOAD_MODEL and CHECKPOINT_FILE in os.listdir():\n",
        "    load_checkpoint(torch.load(CHECKPOINT_FILE), model, optimizer, LEARNING_RATE)\n",
        "\n",
        "test_ds = DRDataset(\n",
        "    images_folder=\"/content/drive/MyDrive/DiabeticRetinopathyDetection/test_resized\",\n",
        "    path_to_csv=\"/content/trainLabel.csv\", # we are not using it\n",
        "    transform=val_transforms,\n",
        "    train=False,\n",
        ")\n",
        "\n",
        "BATCH_SIZE_Test = 32\n",
        "\n",
        "test_loader = DataLoader(\n",
        "    test_ds, batch_size=BATCH_SIZE_Test, num_workers=6, shuffle=False\n",
        ")\n",
        "\n",
        "def make_prediction(model, loader, output_csv=\"submission.csv\"):\n",
        "    preds = []\n",
        "    filenames = []\n",
        "    model.eval()\n",
        "\n",
        "    for x, y, files in tqdm(loader):\n",
        "        x = x.to(DEVICE)\n",
        "        with torch.no_grad():\n",
        "            predictions = model(x)\n",
        "            # Convert MSE floats to integer predictions\n",
        "            predictions[predictions < 0.5] = 0\n",
        "            predictions[(predictions >= 0.5) & (predictions < 1.5)] = 1\n",
        "            predictions[(predictions >= 1.5) & (predictions < 2.5)] = 2\n",
        "            predictions[(predictions >= 2.5) & (predictions < 3.5)] = 3\n",
        "            predictions[(predictions >= 3.5) & (predictions < 10000000)] = 4\n",
        "            predictions = predictions.long().squeeze(1)\n",
        "            preds.append(predictions.cpu().numpy())\n",
        "            filenames += files\n",
        "\n",
        "    # concatenate the filename with the predicted label\n",
        "    df = pd.DataFrame({\"image\": filenames, \"level\": np.concatenate(preds, axis=0)})\n",
        "    df.to_csv(output_csv, index=False)\n",
        "    model.train()\n",
        "    print(\"Done with predictions\")\n",
        "\n",
        "make_prediction(model, test_loader, \"submission_.csv\")"
      ],
      "metadata": {
        "id": "qPXgN2zDAkyJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b3fe0d4c-6a54-4f62-80fd-8d45a29649eb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=> Loading checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1675/1675 [08:34<00:00,  3.26it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Done with predictions\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cp /content/drive/MyDrive/DiabeticRetinopathyDetection/b3_18.pth.tar /content/"
      ],
      "metadata": {
        "id": "_bOj8R2ZXGTG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. Combine data from both eyes\n",
        "(Did not use for final submission)"
      ],
      "metadata": {
        "id": "1JSgfZamA8oN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 5. more tricks\n",
        "\n",
        "import torch.nn.functional as F\n",
        "import warnings\n",
        "\n",
        "CHECKPOINT_FILE = \"b3_9.pth.tar\"\n",
        "\n",
        "if LOAD_MODEL and CHECKPOINT_FILE in os.listdir():\n",
        "    load_checkpoint(torch.load(CHECKPOINT_FILE), model, optimizer, LEARNING_RATE)\n",
        "\n",
        "def get_csv_for_blend(loader, model, output_csv_file):\n",
        "    warnings.warn(\"Important to have shuffle=False (and to ensure batch size is even size) when running get_csv_for_blend also set val_transforms to train_loader!\")\n",
        "    model.eval()\n",
        "    filename_first = []\n",
        "    filename_second = []\n",
        "    labels_first = []\n",
        "    labels_second = []\n",
        "    all_features = []\n",
        "\n",
        "    for idx, (images, y, image_files) in enumerate(tqdm(loader)):\n",
        "        images = images.to(DEVICE)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            features = F.adaptive_avg_pool2d(\n",
        "                model.extract_features(images), output_size=1\n",
        "            )\n",
        "            features_logits = features.reshape(features.shape[0] // 2, 2, features.shape[1])\n",
        "            preds = model(images).reshape(images.shape[0] // 2, 2, 1)\n",
        "            new_features = (\n",
        "                torch.cat([features_logits, preds], dim=2)\n",
        "                .view(preds.shape[0], -1)\n",
        "                .cpu()\n",
        "                .numpy()\n",
        "            )\n",
        "            all_features.append(new_features)\n",
        "            filename_first += image_files[::2]\n",
        "            filename_second += image_files[1::2]\n",
        "            labels_first.append(y[::2].cpu().numpy())\n",
        "            labels_second.append(y[1::2].cpu().numpy())\n",
        "\n",
        "    all_features = np.concatenate(all_features, axis=0)\n",
        "    df = pd.DataFrame(\n",
        "        data=all_features, columns=[f\"f_{idx}\" for idx in range(all_features.shape[1])]\n",
        "    )\n",
        "    df[\"label_first\"] = np.concatenate(labels_first, axis=0)\n",
        "    df[\"label_second\"] = np.concatenate(labels_second, axis=0)\n",
        "    df[\"file_first\"] = filename_first\n",
        "    df[\"file_second\"] = filename_second\n",
        "    df.to_csv(output_csv_file, index=False)\n",
        "    model.train()\n",
        "\n",
        "train_ds = DRDataset(\n",
        "    images_folder=\"/content/drive/MyDrive/DiabeticRetinopathyDetection/train_resized\",\n",
        "    path_to_csv=\"/content/trainLabel.csv\",\n",
        "    transform=val_transforms,\n",
        ")\n",
        "\n",
        "train_loader = DataLoader(\n",
        "    train_ds,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    num_workers=NUM_WORKERS,\n",
        "    pin_memory=PIN_MEMORY,\n",
        "    shuffle=True,\n",
        ")\n",
        "\n",
        "# get_csv_for_blend(val_loader, model, \"/content/drive/MyDrive/DiabeticRetinopathyDetection/val_blend.csv\")\n",
        "get_csv_for_blend(train_loader, model, \"/content/drive/MyDrive/DiabeticRetinopathyDetection/train_blend.csv\")\n",
        "get_csv_for_blend(test_loader, model, \"/content/drive/MyDrive/DiabeticRetinopathyDetection/test_blend.csv\")\n",
        "\n",
        "def make_prediction(model, loader, file):\n",
        "    preds = []\n",
        "    filenames = []\n",
        "    model.eval()\n",
        "\n",
        "    for x, y, files in tqdm(loader):\n",
        "        x = x.to(DEVICE)\n",
        "        with torch.no_grad():\n",
        "            predictions = model(x)\n",
        "            # Convert MSE floats to integer predictions\n",
        "            predictions[predictions < 0.5] = 0\n",
        "            predictions[(predictions >= 0.5) & (predictions < 1.5)] = 1\n",
        "            predictions[(predictions >= 1.5) & (predictions < 2.5)] = 2\n",
        "            predictions[(predictions >= 2.5) & (predictions < 3.5)] = 3\n",
        "            predictions[(predictions >= 3.5) & (predictions < 100)] = 4\n",
        "            predictions = predictions.long().view(-1)\n",
        "            y = y.view(-1)\n",
        "\n",
        "            preds.append(predictions.cpu().numpy())\n",
        "            filenames += map(list, zip(files[0], files[1]))\n",
        "\n",
        "    filenames = [item for sublist in filenames for item in sublist]\n",
        "    df = pd.DataFrame({\"image\": filenames, \"level\": np.concatenate(preds, axis=0)})\n",
        "    df.to_csv(file, index=False)\n",
        "    model.train()\n",
        "    print(\"Done with predictions\")\n",
        "\n",
        "\n",
        "class MyDataset(Dataset):\n",
        "    def __init__(self, csv_file):\n",
        "        self.csv = pd.read_csv(csv_file)\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.csv.shape[0]\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        example = self.csv.iloc[index, :]\n",
        "        features = example.iloc[: example.shape[0] - 4].to_numpy().astype(np.float32)\n",
        "        labels = example.iloc[-4:-2].to_numpy().astype(np.int64)\n",
        "        filenames = example.iloc[-2:].values.tolist()\n",
        "        return features, labels, filenames\n",
        "\n",
        "\n",
        "class MyModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.model = nn.Sequential(\n",
        "            nn.BatchNorm1d((1536 + 1) * 2),\n",
        "            nn.Linear((1536+1) * 2, 500),\n",
        "            nn.BatchNorm1d(500),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.2),\n",
        "            nn.Linear(500, 100),\n",
        "            nn.BatchNorm1d(100),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.2),\n",
        "            nn.Linear(100, 2),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.model(x)"
      ],
      "metadata": {
        "id": "6UpENdwi_jT0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aaa9b83f-7bcc-4fc9-f5fb-1d5457c765e1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=> Loading checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-22-35b5e6bda93c>:17: UserWarning: Important to have shuffle=False (and to ensure batch size is even size) when running get_csv_for_blend also set val_transforms to train_loader!\n",
            "  warnings.warn(\"Important to have shuffle=False (and to ensure batch size is even size) when running get_csv_for_blend also set val_transforms to train_loader!\")\n",
            " 40%|████      | 427/1060 [08:31<33:12,  3.15s/it]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = MyModel().to(DEVICE)\n",
        "ds = MyDataset(csv_file=\"train/train_blend.csv\")\n",
        "loader = DataLoader(ds, batch_size=256, num_workers=3, pin_memory=True, shuffle=True)\n",
        "ds_val = MyDataset(csv_file=\"train/val_blend.csv\")\n",
        "loader_val = DataLoader(\n",
        "    ds_val, batch_size=256, num_workers=3, pin_memory=True, shuffle=True\n",
        ")\n",
        "ds_test = MyDataset(csv_file=\"train/test_blend.csv\")\n",
        "loader_test = DataLoader(\n",
        "    ds_test, batch_size=256, num_workers=2, pin_memory=True, shuffle=False\n",
        ")\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-4, weight_decay=1e-5)\n",
        "loss_fn = nn.MSELoss()\n",
        "\n",
        "if LOAD_MODEL and \"linear.pth.tar\" in os.listdir():\n",
        "    load_checkpoint(torch.load(\"linear.pth.tar\"), model, optimizer, lr=1e-4)\n",
        "    model.train()\n",
        "\n",
        "for _ in range(5):\n",
        "    losses = []\n",
        "    for x, y, files in tqdm(loader_val):\n",
        "        x = x.to(DEVICE).float()\n",
        "        y = y.to(DEVICE).view(-1).float()\n",
        "\n",
        "        # forward\n",
        "        scores = model(x).view(-1)\n",
        "        loss = loss_fn(scores, y)\n",
        "        losses.append(loss.item())\n",
        "\n",
        "        # backward\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "\n",
        "        # gradient descent or adam step\n",
        "        optimizer.step()\n",
        "\n",
        "    print(f\"Loss: {sum(losses)/len(losses)}\")\n",
        "\n",
        "if SAVE_MODEL:\n",
        "    checkpoint = {\"state_dict\": model.state_dict(), \"optimizer\": optimizer.state_dict()}\n",
        "    save_checkpoint(checkpoint, filename=\"linear.pth.tar\")\n",
        "\n",
        "preds, labels = check_accuracy(loader_val, model)\n",
        "print(cohen_kappa_score(labels, preds, weights=\"quadratic\"))\n",
        "\n",
        "preds, labels = check_accuracy(loader, model)\n",
        "print(cohen_kappa_score(labels, preds, weights=\"quadratic\"))\n",
        "\n",
        "make_prediction(model, loader_test, \"test_preds.csv\")"
      ],
      "metadata": {
        "id": "FKsBH56vB-xn"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}